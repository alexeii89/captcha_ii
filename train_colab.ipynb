{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Обучение модели CRNN для распознавания капчи\n",
        "\n",
        "Этот notebook предназначен для обучения модели на Google Colab.\n",
        "\n",
        "## Шаги:\n",
        "1. Установка зависимостей\n",
        "2. Загрузка файлов проекта\n",
        "3. Генерация/загрузка датасета\n",
        "4. Обучение модели\n",
        "5. Сохранение результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка зависимостей\n",
        "%pip install captcha>=0.7.1 tqdm Pillow torch torchvision matplotlib google\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка файлов проекта\n",
        "\n",
        "Вы можете загрузить файлы проекта несколькими способами:\n",
        "\n",
        "### Вариант 1: Загрузить с GitHub (если проект в репозитории)\n",
        "### Вариант 2: Загрузить файлы вручную через файловую систему Colab\n",
        "### Вариант 3: Создать файлы прямо в Colab (клетки ниже)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ℹ Не удалось подключить Google Drive: mount failed\n",
            "ℹ Это нормально - файлы будут созданы в следующих ячейках\n",
            "Готово к созданию/загрузке файлов проекта\n"
          ]
        }
      ],
      "source": [
        "# Создаем необходимые файлы проекта\n",
        "# Если файлы уже загружены, эту ячейку можно пропустить\n",
        "\n",
        "import os\n",
        "os.makedirs('project', exist_ok=True)\n",
        "\n",
        "# Если у вас есть файлы в Google Drive, подключите его (НЕОБЯЗАТЕЛЬНО):\n",
        "# Эта ячейка опциональна - файлы будут созданы в следующих ячейках\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    \n",
        "    # Копируем файлы, если они есть\n",
        "    if os.path.exists('/content/drive/MyDrive/captcha_ii'):\n",
        "        import shutil\n",
        "        src = '/content/drive/MyDrive/captcha_ii'\n",
        "        dst = './project'\n",
        "        try:\n",
        "            for item in os.listdir(src):\n",
        "                s = os.path.join(src, item)\n",
        "                d = os.path.join(dst, item)\n",
        "                if os.path.isdir(s):\n",
        "                    shutil.copytree(s, d, dirs_exist_ok=True)\n",
        "                else:\n",
        "                    shutil.copy2(s, d)\n",
        "            print(\"✓ Файлы загружены из Google Drive\")\n",
        "        except Exception as copy_error:\n",
        "            print(f\"ℹ Файлы не найдены в Drive или ошибка копирования: {copy_error}\")\n",
        "            print(\"ℹ Файлы будут созданы в следующих ячейках\")\n",
        "    else:\n",
        "        print(\"ℹ Папка captcha_ii не найдена в Drive. Файлы будут созданы в следующих ячейках.\")\n",
        "except Exception as e:\n",
        "    print(f\"ℹ Не удалось подключить Google Drive: {e}\")\n",
        "    print(\"ℹ Это нормально - файлы будут созданы в следующих ячейках\")\n",
        "\n",
        "print(\"Готово к созданию/загрузке файлов проекта\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'captcha_ii'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 0), reused 10 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 17.67 KiB | 8.83 MiB/s, done.\n",
            "/content/captcha_ii\n",
            "cp: 'model.py' and './model.py' are the same file\n",
            "cp: 'dataset_loader.py' and './dataset_loader.py' are the same file\n",
            "cp: 'train.py' and './train.py' are the same file\n",
            "cp: 'main.py' and './main.py' are the same file\n",
            "Файлы должны быть в текущей директории\n",
            "-rw-r--r-- 1 root root  7548 Dec 10 06:10 dataset_loader.py\n",
            "-rw-r--r-- 1 root root  3190 Dec 10 06:10 main.py\n",
            "-rw-r--r-- 1 root root  5126 Dec 10 06:10 model.py\n",
            "-rw-r--r-- 1 root root  3521 Dec 10 06:10 predict.py\n",
            "-rw-r--r-- 1 root root 10180 Dec 10 06:10 train.py\n"
          ]
        }
      ],
      "source": [
        "# Загружаем файлы model.py, dataset_loader.py, train.py\n",
        "# Если файлы загружены через Drive или GitHub, раскомментируйте соответствующие строки\n",
        "\n",
        "# Для загрузки с GitHub:\n",
        "!git clone https://github.com/alexeii89/captcha_ii.git\n",
        "%cd captcha_ii\n",
        "\n",
        "# Или загрузите файлы через интерфейс Colab (Files -> Upload)\n",
        "# Затем скопируйте в рабочую директорию:\n",
        "!cp model.py dataset_loader.py train.py main.py ./\n",
        "\n",
        "print(\"Файлы должны быть в текущей директории\")\n",
        "!ls -la *.py 2>/dev/null || echo \"Файлы .py не найдены. Загрузите их через интерфейс Colab или используйте следующий вариант.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Вариант: Создать файлы прямо здесь\n",
        "\n",
        "Если файлы не загружены, можно прочитать их из локальных файлов и создать в Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем файл model.py\n",
        "%%writefile model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CRNN (Convolutional Recurrent Neural Network) модель для распознавания капчи.\n",
        "    Использует CNN для извлечения признаков и RNN (LSTM) для обработки последовательности.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes, img_height=80, img_width=200):\n",
        "        super(CRNN, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        \n",
        "        # CNN для извлечения признаков\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "            \n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "            \n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
        "            \n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
        "            \n",
        "            nn.Conv2d(512, 512, kernel_size=2, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        self.rnn_input_size = 512\n",
        "        self.hidden_size = 256\n",
        "        self.num_layers = 2\n",
        "        \n",
        "        self.rnn = nn.LSTM(\n",
        "            self.rnn_input_size,\n",
        "            self.hidden_size,\n",
        "            self.num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Linear(self.hidden_size * 2, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv_features = self.cnn(x)\n",
        "        batch_size, channels, height, width = conv_features.size()\n",
        "        \n",
        "        if height > 1:\n",
        "            conv_features = conv_features.mean(dim=2)\n",
        "        else:\n",
        "            conv_features = conv_features.squeeze(2)\n",
        "        \n",
        "        conv_features = conv_features.permute(0, 2, 1)\n",
        "        rnn_out, _ = self.rnn(conv_features)\n",
        "        output = self.fc(rnn_out)\n",
        "        output = output.log_softmax(2)\n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "def decode_predictions(predictions, dataset):\n",
        "    pred_indices = predictions.argmax(dim=2)\n",
        "    decoded_texts = []\n",
        "    for pred_seq in pred_indices:\n",
        "        text = dataset.decode(pred_seq)\n",
        "        decoded_texts.append(text)\n",
        "    return decoded_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем файл dataset_loader.py\n",
        "%%writefile dataset_loader.py\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import platform\n",
        "\n",
        "\n",
        "class CaptchaDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, characters, transform=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.characters = characters\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.char_to_idx = {char: idx + 1 for idx, char in enumerate(characters)}\n",
        "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
        "        self.idx_to_char[0] = ''\n",
        "        self.num_classes = len(characters) + 1\n",
        "        \n",
        "        self.image_files = [f for f in os.listdir(dataset_dir) if f.endswith('.png')]\n",
        "        print(f\"Загружено {len(self.image_files)} изображений\")\n",
        "        print(f\"Количество символов: {len(characters)}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.image_files[idx]\n",
        "        filepath = os.path.join(self.dataset_dir, filename)\n",
        "        image = Image.open(filepath).convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        text = filename.replace('.png', '').rsplit('_', 1)[0]\n",
        "        target = [self.char_to_idx[char] for char in text]\n",
        "        target_length = len(target)\n",
        "        \n",
        "        return image, torch.tensor(target, dtype=torch.long), target_length, text\n",
        "    \n",
        "    def decode(self, indices):\n",
        "        if isinstance(indices, torch.Tensor):\n",
        "            indices = indices.cpu().numpy()\n",
        "        decoded = []\n",
        "        prev_idx = None\n",
        "        for idx in indices:\n",
        "            if idx != 0 and idx != prev_idx and idx < len(self.char_to_idx) + 1:\n",
        "                char = self.idx_to_char.get(idx, '')\n",
        "                if char:\n",
        "                    decoded.append(char)\n",
        "            prev_idx = idx\n",
        "        return ''.join(decoded)\n",
        "\n",
        "\n",
        "class DatasetWrapper(torch.utils.data.Dataset):\n",
        "    def __init__(self, subset, original_dataset):\n",
        "        self.subset = subset\n",
        "        self.dataset = original_dataset\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.subset[idx]\n",
        "    \n",
        "    @property\n",
        "    def char_to_idx(self):\n",
        "        return self.dataset.char_to_idx\n",
        "    \n",
        "    @property\n",
        "    def idx_to_char(self):\n",
        "        return self.dataset.idx_to_char\n",
        "    \n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return self.dataset.num_classes\n",
        "    \n",
        "    def decode(self, indices):\n",
        "        return self.dataset.decode(indices)\n",
        "\n",
        "\n",
        "def get_data_loaders(dataset_dir, characters, batch_size=32, train_split=0.8, num_workers=None):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    \n",
        "    full_dataset = CaptchaDataset(dataset_dir, characters, transform=transform)\n",
        "    \n",
        "    train_size = int(train_split * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_subset, val_subset = torch.utils.data.random_split(\n",
        "        full_dataset, [train_size, val_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    \n",
        "    train_dataset = DatasetWrapper(train_subset, full_dataset)\n",
        "    val_dataset = DatasetWrapper(val_subset, full_dataset)\n",
        "    \n",
        "    if num_workers is None:\n",
        "        num_workers = 2  # Для Colab используем 2 workers\n",
        "    \n",
        "    use_pin_memory = torch.cuda.is_available()\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, collate_fn=collate_fn, pin_memory=use_pin_memory\n",
        "    )\n",
        "    \n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, collate_fn=collate_fn, pin_memory=use_pin_memory\n",
        "    )\n",
        "    \n",
        "    return train_loader, val_loader, full_dataset\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets, target_lengths, texts = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    max_len = max(target_lengths)\n",
        "    padded_targets = torch.zeros(len(targets), max_len, dtype=torch.long)\n",
        "    for i, (target, length) in enumerate(zip(targets, target_lengths)):\n",
        "        padded_targets[i, :length] = target\n",
        "    target_lengths = torch.tensor(target_lengths, dtype=torch.long)\n",
        "    return images, padded_targets, target_lengths, texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем файл main.py для генерации датасета\n",
        "%%writefile main.py\n",
        "import os\n",
        "import random\n",
        "from captcha.image import ImageCaptcha\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def generate_captcha_dataset(num_images=50000):\n",
        "    \"\"\"\n",
        "    Генерирует датасет из изображений капчи с русскими буквами и цифрами.\n",
        "    Имя файла соответствует тексту на капче.\n",
        "    \n",
        "    Args:\n",
        "        num_images: Количество изображений для генерации (по умолчанию 50000)\n",
        "    \"\"\"\n",
        "    dataset_dir = 'dataset'\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "    \n",
        "    russian_letters = 'АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ'\n",
        "    numbers = '0123456789'\n",
        "    characters = russian_letters + numbers\n",
        "    \n",
        "    min_length = 4\n",
        "    max_length = 6\n",
        "    \n",
        "    image_captcha = ImageCaptcha(width=200, height=80)\n",
        "    created_files = set()\n",
        "    \n",
        "    print(f\"Начинаю генерацию {num_images} изображений капчи...\")\n",
        "    print(f\"Символы: {characters}\")\n",
        "    print(f\"Длина текста: {min_length}-{max_length} символов\")\n",
        "    print(f\"Папка для сохранения: {dataset_dir}\")\n",
        "    \n",
        "    for i in tqdm(range(num_images), desc=\"Генерация капчи\"):\n",
        "        length = random.randint(min_length, max_length)\n",
        "        captcha_text = ''.join(random.choices(characters, k=length))\n",
        "        filename = f\"{captcha_text}.png\"\n",
        "        filepath = os.path.join(dataset_dir, filename)\n",
        "        \n",
        "        counter = 1\n",
        "        while filename in created_files:\n",
        "            filename = f\"{captcha_text}_{counter}.png\"\n",
        "            filepath = os.path.join(dataset_dir, filename)\n",
        "            counter += 1\n",
        "        \n",
        "        created_files.add(filename)\n",
        "        image = image_captcha.generate_image(captcha_text)\n",
        "        image.save(filepath)\n",
        "    \n",
        "    print(f\"\\n✓ Готово! Сгенерировано {num_images} изображений в папке '{dataset_dir}'\")\n",
        "    print(f\"✓ Уникальных файлов: {len(created_files)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_captcha_dataset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Генерация датасета\n",
        "\n",
        "Теперь сгенерируем датасет. Вы можете:\n",
        "1. Сгенерировать на Colab (займет время)\n",
        "2. Загрузить готовый датасет с Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "generate_captcha_dataset() got an unexpected keyword argument 'num_images'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2710932557.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Генерируем 50000 изображений (можете уменьшить для теста)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgenerate_captcha_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: generate_captcha_dataset() got an unexpected keyword argument 'num_images'"
          ]
        }
      ],
      "source": [
        "# Вариант 1: Генерация датасета прямо в Colab\n",
        "# Раскомментируйте следующие строки, если хотите сгенерировать датасет\n",
        "\n",
        "from main import generate_captcha_dataset\n",
        "\n",
        "# Генерируем 50000 изображений (можете уменьшить для теста)\n",
        "generate_captcha_dataset(num_images=50000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Вариант 2: Загрузка датасета с Google Drive (ОПЦИОНАЛЬНО)\n",
        "# Раскомментируйте и запустите, если у вас уже есть датасет в Drive\n",
        "\n",
        "# try:\n",
        "#     from google.colab import drive\n",
        "#     drive.mount('/content/drive', force_remount=False)\n",
        "#     \n",
        "#     # Создаем симлинк на папку с датасетом\n",
        "#     if os.path.exists('/content/drive/MyDrive/captcha_ii/dataset'):\n",
        "#         !ln -s /content/drive/MyDrive/captcha_ii/dataset ./dataset\n",
        "#         print(\"✓ Датасет подключен из Google Drive\")\n",
        "#     else:\n",
        "#         print(\"ℹ Датасет не найден в Drive, будет сгенерирован новый\")\n",
        "# except Exception as e:\n",
        "#     print(f\"ℹ Не удалось подключить Drive: {e}\")\n",
        "#     print(\"ℹ Датасет будет сгенерирован в следующей ячейке\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Обучение модели\n",
        "\n",
        "Теперь запускаем обучение. Убедитесь, что датасет готов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импортируем необходимые модули\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from model import CRNN, decode_predictions\n",
        "from dataset_loader import get_data_loaders\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функции для обучения (можно вынести в train.py, но для простоты оставим здесь)\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device, dataset):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    progress_bar = tqdm(train_loader, desc=\"Обучение\")\n",
        "    for images, targets, target_lengths, texts in progress_bar:\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "        target_lengths = target_lengths.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        outputs = outputs.permute(1, 0, 2)\n",
        "        \n",
        "        input_lengths = torch.full(\n",
        "            size=(outputs.size(1),),\n",
        "            fill_value=outputs.size(0),\n",
        "            dtype=torch.long\n",
        "        ).to(device)\n",
        "        \n",
        "        loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            pred_outputs = model(images)\n",
        "            decoded_preds = decode_predictions(pred_outputs, dataset)\n",
        "            \n",
        "            for pred, true in zip(decoded_preds, texts):\n",
        "                if pred == true:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "        \n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{100 * correct / total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    return total_loss / len(train_loader), 100 * correct / total if total > 0 else 0\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion, device, dataset):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(val_loader, desc=\"Валидация\")\n",
        "        for images, targets, target_lengths, texts in progress_bar:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            target_lengths = target_lengths.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            outputs = outputs.permute(1, 0, 2)\n",
        "            \n",
        "            input_lengths = torch.full(\n",
        "                size=(outputs.size(1),),\n",
        "                fill_value=outputs.size(0),\n",
        "                dtype=torch.long\n",
        "            ).to(device)\n",
        "            \n",
        "            loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            pred_outputs = model(images)\n",
        "            decoded_preds = decode_predictions(pred_outputs, dataset)\n",
        "            \n",
        "            for pred, true in zip(decoded_preds, texts):\n",
        "                if pred == true:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "            \n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{100 * correct / total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    return total_loss / len(val_loader), 100 * correct / total if total > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Настройки обучения\n",
        "russian_letters = 'АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ'\n",
        "numbers = '0123456789'\n",
        "characters = russian_letters + numbers\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "DATASET_DIR = 'dataset'\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Настройки обучения\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Эпох: {EPOCHS}\")\n",
        "print(f\"Размер батча: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Количество символов: {len(characters)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "# Загружаем данные\n",
        "print(\"\\nЗагрузка датасета...\")\n",
        "train_loader, val_loader, dataset = get_data_loaders(\n",
        "    dataset_dir=DATASET_DIR,\n",
        "    characters=characters,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    train_split=0.8,\n",
        "    num_workers=2  # Для Colab\n",
        ")\n",
        "\n",
        "print(f\"Обучающих примеров: {len(train_loader.dataset)}\")\n",
        "print(f\"Валидационных примеров: {len(val_loader.dataset)}\")\n",
        "\n",
        "# Создаем модель\n",
        "model = CRNN(num_classes=len(characters) + 1).to(device)\n",
        "print(f\"\\nМодель создана. Параметров: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Функция потерь и оптимизатор\n",
        "criterion = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# История\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "best_val_acc = 0\n",
        "\n",
        "print(\"\\nНачинаем обучение...\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Цикл обучения\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nЭпоха {epoch + 1}/{EPOCHS}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, dataset)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device, dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    \n",
        "    old_lr = optimizer.param_groups[0]['lr']\n",
        "    scheduler.step(val_loss)\n",
        "    new_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    print(f\"\\nРезультаты эпохи {epoch + 1}:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    if old_lr != new_lr:\n",
        "        print(f\"  Learning rate: {old_lr:.6f} -> {new_lr:.6f}\")\n",
        "    \n",
        "    # Сохраняем лучшую модель\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_acc': val_acc,\n",
        "            'characters': characters,\n",
        "        }, 'models/best_model.pth')\n",
        "        print(f\"  ✓ Сохранена лучшая модель (Val Acc: {val_acc:.2f}%)\")\n",
        "    \n",
        "    # Чекпоинт каждые 10 эпох\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'train_accs': train_accs,\n",
        "            'val_accs': val_accs,\n",
        "            'characters': characters,\n",
        "        }, f'models/checkpoint_epoch_{epoch + 1}.pth')\n",
        "\n",
        "# Финальное сохранение\n",
        "torch.save({\n",
        "    'epoch': EPOCHS,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_losses': train_losses,\n",
        "    'val_losses': val_losses,\n",
        "    'train_accs': train_accs,\n",
        "    'val_accs': val_accs,\n",
        "    'characters': characters,\n",
        "}, 'models/final_model.pth')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Обучение завершено!\")\n",
        "print(f\"Лучшая точность на валидации: {best_val_acc:.2f}%\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Строим графики\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "ax1.plot(train_losses, label='Train Loss')\n",
        "ax1.plot(val_losses, label='Val Loss')\n",
        "ax1.set_xlabel('Эпоха')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('История Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "ax2.plot(train_accs, label='Train Acc')\n",
        "ax2.plot(val_accs, label='Val Acc')\n",
        "ax2.set_xlabel('Эпоха')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('История Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('models/training_history.png')\n",
        "plt.show()\n",
        "\n",
        "print(\"График сохранен: models/training_history.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сохранение результатов\n",
        "\n",
        "Сохраните модель в Google Drive для дальнейшего использования.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение в Google Drive (ОПЦИОНАЛЬНО)\n",
        "# Запустите эту ячейку, чтобы сохранить модели в Drive\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    import shutil\n",
        "    \n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    \n",
        "    # Создаем папку, если её нет\n",
        "    drive_path = '/content/drive/MyDrive/captcha_ii'\n",
        "    os.makedirs(drive_path, exist_ok=True)\n",
        "    \n",
        "    # Копируем модели\n",
        "    models_src = './models'\n",
        "    models_dst = os.path.join(drive_path, 'models')\n",
        "    \n",
        "    if os.path.exists(models_src):\n",
        "        if os.path.exists(models_dst):\n",
        "            shutil.rmtree(models_dst)\n",
        "        shutil.copytree(models_src, models_dst)\n",
        "        print(\"✓ Модели сохранены в Google Drive:\")\n",
        "        print(f\"  /content/drive/MyDrive/captcha_ii/models/\")\n",
        "    else:\n",
        "        print(\"ℹ Папка models не найдена. Сначала запустите обучение.\")\n",
        "except Exception as e:\n",
        "    print(f\"ℹ Не удалось сохранить в Drive: {e}\")\n",
        "    print(\"\\nℹ Используйте скачивание через интерфейс Colab:\")\n",
        "    print(\"   1. Откройте панель Files (слева)\")\n",
        "    print(\"   2. Перейдите в папку models/\")\n",
        "    print(\"   3. Нажмите правой кнопкой на best_model.pth\")\n",
        "    print(\"   4. Выберите 'Download'\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
