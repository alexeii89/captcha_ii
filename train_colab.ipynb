{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ CRNN –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∫–∞–ø—á–∏\n",
    "\n",
    "–≠—Ç–æ—Ç notebook –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ Google Colab.\n",
    "\n",
    "## –®–∞–≥–∏:\n",
    "1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "2. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è/–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "%pip install captcha>=0.7.1 tqdm Pillow torch torchvision matplotlib google\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "\n",
    "–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏:\n",
    "\n",
    "### –í–∞—Ä–∏–∞–Ω—Ç 1: –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å GitHub (–µ—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏)\n",
    "### –í–∞—Ä–∏–∞–Ω—Ç 2: –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É Colab\n",
    "### –í–∞—Ä–∏–∞–Ω—Ç 3: –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª—ã –ø—Ä—è–º–æ –≤ Colab (–∫–ª–µ—Ç–∫–∏ –Ω–∏–∂–µ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'captcha_ii'...\n",
      "remote: Enumerating objects: 20, done.\u001b[K\n",
      "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 20 (delta 7), reused 18 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (20/20), 75.94 KiB | 25.31 MiB/s, done.\n",
      "Resolving deltas: 100% (7/7), done.\n",
      "/content/captcha_ii\n",
      "cp: 'model.py' and './model.py' are the same file\n",
      "cp: 'dataset_loader.py' and './dataset_loader.py' are the same file\n",
      "cp: 'train.py' and './train.py' are the same file\n",
      "cp: 'main.py' and './main.py' are the same file\n",
      "–§–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
      "-rw-r--r-- 1 root root  7548 Dec 11 06:39 dataset_loader.py\n",
      "-rw-r--r-- 1 root root  3259 Dec 11 06:39 main.py\n",
      "-rw-r--r-- 1 root root  5126 Dec 11 06:39 model.py\n",
      "-rw-r--r-- 1 root root  3521 Dec 11 06:39 predict.py\n",
      "-rw-r--r-- 1 root root 10166 Dec 11 06:39 train.py\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã model.py, dataset_loader.py, train.py\n",
    "# –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã —á–µ—Ä–µ–∑ Drive –∏–ª–∏ GitHub, —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏\n",
    "\n",
    "# –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å GitHub:\n",
    "!git clone https://github.com/alexeii89/captcha_ii.git\n",
    "%cd captcha_ii\n",
    "\n",
    "# –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Colab (Files -> Upload)\n",
    "# –ó–∞—Ç–µ–º —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤ —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é:\n",
    "!cp model.py dataset_loader.py train.py main.py ./\n",
    "\n",
    "print(\"–§–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\")\n",
    "!ls -la *.py 2>/dev/null || echo \"–§–∞–π–ª—ã .py –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Ö —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Colab –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í–∞—Ä–∏–∞–Ω—Ç: –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª—ã –ø—Ä—è–º–æ –∑–¥–µ—Å—å\n",
    "\n",
    "–ï—Å–ª–∏ —Ñ–∞–π–ª—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏—Ö –∏–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ–∑–¥–∞—Ç—å –≤ Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "**–í–∞–∂–Ω–æ:** –ï—Å–ª–∏ –≤—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å–æ–∑–¥–∞–ª–∏ —Ñ–∞–π–ª `main.py` –≤ —è—á–µ–π–∫–µ –≤—ã—à–µ, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç. –í—ã –º–æ–∂–µ—Ç–µ:\n",
    "1. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ Colab (–∑–∞–π–º–µ—Ç –≤—Ä–µ–º—è) - —è—á–µ–π–∫–∞ 10\n",
    "2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å Google Drive - —è—á–µ–π–∫–∞ 11 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = input(\"–í–≤–µ–¥–∏—Ç–µ IP –∏–ª–∏ –¥–æ–º–µ–Ω —Å–µ—Ä–≤–µ—Ä–∞: \")\n",
    "USER = input(\"–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: \")\n",
    "REMOTE_PATH = input(\"–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ: \")\n",
    "PASSWORD = input(\"–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞...\n",
      "–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é 50000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–∞–ø—á–∏...\n",
      "–°–∏–º–≤–æ–ª—ã: –ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø0123456789\n",
      "–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: 4-6 —Å–∏–º–≤–æ–ª–æ–≤\n",
      "–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–ø—á–∏: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [12:13<00:00, 68.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì –ì–æ—Ç–æ–≤–æ! –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ 50000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ 'dataset'\n",
      "‚úì –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: 50000\n",
      "\n",
      "‚úì –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# –í–∞—Ä–∏–∞–Ω—Ç 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä—è–º–æ –≤ Colab\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª main.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é\n",
    "import os\n",
    "if not os.path.exists('main.py'):\n",
    "    raise FileNotFoundError(\"–§–∞–π–ª main.py –Ω–µ –Ω–∞–π–¥–µ–Ω! –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É 8, –≥–¥–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è main.py\")\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥—É–ª—å (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –æ–Ω —É–∂–µ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω)\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –º–æ–¥—É–ª—å –∏–∑ –∫—ç—à–∞, –µ—Å–ª–∏ –æ–Ω –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω —Ä–∞–Ω–µ–µ\n",
    "if 'main' in sys.modules:\n",
    "    del sys.modules['main']\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å –∑–∞–Ω–æ–≤–æ\n",
    "from main import generate_captcha_dataset\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n",
    "# –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1000)\n",
    "# –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 50000\n",
    "print(\"–ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞...\")\n",
    "generate_captcha_dataset()\n",
    "print(\"\\n‚úì –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from model import CRNN, decode_predictions\n",
    "from dataset_loader import get_data_loaders\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ train.py, –Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –æ—Å—Ç–∞–≤–∏–º –∑–¥–µ—Å—å)\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, dataset):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"–û–±—É—á–µ–Ω–∏–µ\")\n",
    "    for images, targets, target_lengths, texts in progress_bar:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        target_lengths = target_lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "        \n",
    "        input_lengths = torch.full(\n",
    "            size=(outputs.size(1),),\n",
    "            fill_value=outputs.size(0),\n",
    "            dtype=torch.long\n",
    "        ).to(device)\n",
    "        \n",
    "        loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_outputs = model(images)\n",
    "            decoded_preds = decode_predictions(pred_outputs, dataset)\n",
    "            \n",
    "            for pred, true in zip(decoded_preds, texts):\n",
    "                if pred == true:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100 * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(train_loader), 100 * correct / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device, dataset):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"–í–∞–ª–∏–¥–∞—Ü–∏—è\")\n",
    "        for images, targets, target_lengths, texts in progress_bar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            target_lengths = target_lengths.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "            \n",
    "            input_lengths = torch.full(\n",
    "                size=(outputs.size(1),),\n",
    "                fill_value=outputs.size(0),\n",
    "                dtype=torch.long\n",
    "            ).to(device)\n",
    "            \n",
    "            loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred_outputs = model(images)\n",
    "            decoded_preds = decode_predictions(pred_outputs, dataset)\n",
    "            \n",
    "            for pred, true in zip(decoded_preds, texts):\n",
    "                if pred == true:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * correct / total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return total_loss / len(val_loader), 100 * correct / total if total > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è\n",
      "============================================================\n",
      "–≠–ø–æ—Ö: 50\n",
      "–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: 32\n",
      "Learning rate: 0.001\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: 34\n",
      "============================================================\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n",
      "\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...\n",
      "–ó–∞–≥—Ä—É–∂–µ–Ω–æ 50000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: 34\n",
      "–û–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: 40000\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: 10000\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞. –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 8,726,307\n",
      "\n",
      "–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "# –ò—Å–∫–ª—é—á–∞–µ–º –¨, –™, –ô, –û, –©, –ó - –∏—Ö –Ω–µ—Ç –≤ –∫–∞–ø—á–µ\n",
    "russian_letters = '–ê–ë–í–ì–î–ï–ñ–ò–ö–õ–ú–ù–ü–†–°–¢–£–§–•–¶–ß–®–´–≠–Æ–Ø'\n",
    "numbers = '1234567890'\n",
    "characters = russian_letters + numbers\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "DATASET_DIR = 'dataset'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"–≠–ø–æ—Ö: {EPOCHS}\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(characters)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "print(\"\\n–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...\")\n",
    "train_loader, val_loader, dataset = get_data_loaders(\n",
    "    dataset_dir=DATASET_DIR,\n",
    "    characters=characters,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_split=0.8,\n",
    "    num_workers=2  # –î–ª—è Colab\n",
    ")\n",
    "\n",
    "print(f\"–û–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(train_loader.dataset)}\")\n",
    "print(f\"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(val_loader.dataset)}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = CRNN(num_classes=len(characters) + 1).to(device)\n",
    "print(f\"\\n–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞. –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "criterion = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# –ò—Å—Ç–æ—Ä–∏—è\n",
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "best_val_acc = 0\n",
    "\n",
    "print(\"\\n–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–≠–ø–æ—Ö–∞ 1/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–û–±—É—á–µ–Ω–∏–µ:   0%|          | 0/1250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/content/captcha_ii/dataset_loader.py\", line 81, in __getitem__\n    return self.subset[idx]\n           ~~~~~~~~~~~^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\", line 408, in __getitem__\n    return self.dataset[self.indices[idx]]\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/content/captcha_ii/dataset_loader.py\", line 50, in __getitem__\n    target = [self.char_to_idx[char] for char in text]\n              ~~~~~~~~~~~~~~~~^^^^^^\nKeyError: '–™'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2925898920.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-2387152376.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, dataset)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"–û–±—É—á–µ–Ω–∏–µ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/content/captcha_ii/dataset_loader.py\", line 81, in __getitem__\n    return self.subset[idx]\n           ~~~~~~~~~~~^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\", line 408, in __getitem__\n    return self.dataset[self.indices[idx]]\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/content/captcha_ii/dataset_loader.py\", line 50, in __getitem__\n    target = [self.char_to_idx[char] for char in text]\n              ~~~~~~~~~~~~~~~~^^^^^^\nKeyError: '–™'\n"
     ]
    }
   ],
   "source": [
    "# –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n–≠–ø–æ—Ö–∞ {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device, dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏ {epoch + 1}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    if old_lr != new_lr:\n",
    "        print(f\"  Learning rate: {old_lr:.6f} -> {new_lr:.6f}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'characters': characters,\n",
    "        }, 'models/best_model.pth')\n",
    "        print(f\"  ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (Val Acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # –ß–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ 10 —ç–ø–æ—Ö\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_accs': train_accs,\n",
    "            'val_accs': val_accs,\n",
    "            'characters': characters,\n",
    "        }, f'models/checkpoint_epoch_{epoch + 1}.pth')\n",
    "\n",
    "# –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "torch.save({\n",
    "    'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accs': train_accs,\n",
    "    'val_accs': val_accs,\n",
    "    'characters': characters,\n",
    "}, 'models/final_model.pth')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
    "print(f\"–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {best_val_acc:.2f}%\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_xlabel('–≠–ø–æ—Ö–∞')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('–ò—Å—Ç–æ—Ä–∏—è Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(train_accs, label='Train Acc')\n",
    "ax2.plot(val_accs, label='Val Acc')\n",
    "ax2.set_xlabel('–≠–ø–æ—Ö–∞')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('–ò—Å—Ç–æ—Ä–∏—è Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/training_history.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: models/training_history.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ SSH\n",
    "\n",
    "–ê—Ä—Ö–∏–≤–∏—Ä—É–π—Ç–µ –ø–∞–ø–∫—É models –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä –ø–æ SSH.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ models –ø–æ SSH\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# ‚öôÔ∏è –ò–ó–ú–ï–ù–ò–¢–ï –≠–¢–ò –ù–ê–°–¢–†–û–ô–ö–ò –ù–ê –°–í–û–ò!\n",
    "       # –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ\n",
    "PORT = 22                          # SSH –ø–æ—Ä—Ç                 # –ü–∞—Ä–æ–ª—å (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω) –∏–ª–∏ None –¥–ª—è SSH –∫–ª—é—á–µ–π\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üì¶ –ê–†–•–ò–í–ê–¶–ò–Ø –ò –ó–ê–ì–†–£–ó–ö–ê MODELS –ü–û SSH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤\n",
    "print(\"\\n1Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞...\")\n",
    "models_dir = './models'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    print(\"‚ùå –ü–∞–ø–∫–∞ models –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!\")\n",
    "    print(\"–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.\")\n",
    "else:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_name = f'models_{timestamp}.zip'\n",
    "    \n",
    "    print(f\"üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞: {archive_name}\")\n",
    "    with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(models_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, '.')\n",
    "                zipf.write(file_path, arcname)\n",
    "                print(f\"  ‚úÖ {arcname}\")\n",
    "    \n",
    "    file_size = os.path.getsize(archive_name) / (1024 * 1024)\n",
    "    print(f\"\\n‚úÖ –ê—Ä—Ö–∏–≤ —Å–æ–∑–¥–∞–Ω: {archive_name} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ —Å–µ—Ä–≤–µ—Ä\n",
    "    if HOST == 'your-server.com':\n",
    "        print(\"\\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã SSH!\")\n",
    "        print(\"–ò–∑–º–µ–Ω–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –Ω–∞—á–∞–ª–µ —Å–∫—Ä–∏–ø—Ç–∞:\")\n",
    "        print(\"  - HOST: –∞–¥—Ä–µ—Å –≤–∞—à–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞\")\n",
    "        print(\"  - USER: –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\")\n",
    "        print(\"  - REMOTE_PATH: –ø—É—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ\")\n",
    "        print(\"  - PASSWORD: –ø–∞—Ä–æ–ª—å (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ)\")\n",
    "    else:\n",
    "        print(f\"\\n2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ {USER}@{HOST}...\")\n",
    "        print(f\"   –ü—É—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ: {REMOTE_PATH}\")\n",
    "        \n",
    "        if PASSWORD:\n",
    "            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º sshpass –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "            try:\n",
    "                subprocess.run(['which', 'sshpass'], check=True,\n",
    "                             stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "            except:\n",
    "                print(\"üì• –£—Å—Ç–∞–Ω–æ–≤–∫–∞ sshpass...\")\n",
    "                subprocess.run(['apt-get', 'install', '-y', 'sshpass'], check=True)\n",
    "            \n",
    "            cmd = ['sshpass', '-p', PASSWORD, 'scp', '-P', str(PORT),\n",
    "                   '-o', 'StrictHostKeyChecking=no', archive_name,\n",
    "                   f'{USER}@{HOST}:{REMOTE_PATH}']\n",
    "        else:\n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º SSH –∫–ª—é—á–∏\n",
    "            cmd = ['scp', '-P', str(PORT), '-o', 'StrictHostKeyChecking=no',\n",
    "                   archive_name, f'{USER}@{HOST}:{REMOTE_PATH}']\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, check=True)\n",
    "            print(f\"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!\")\n",
    "            print(f\"\\nüìÅ –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ: {REMOTE_PATH}{archive_name}\")\n",
    "            print(f\"\\nüí° –î–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:\")\n",
    "            print(f\"   ssh {USER}@{HOST} 'cd {REMOTE_PATH} && unzip -q {archive_name}'\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏!\")\n",
    "            print(f\"\\nüí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\")\n",
    "            print(\"   - –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å HOST, USER, REMOTE_PATH\")\n",
    "            print(\"   - –ù–∞–ª–∏—á–∏–µ SSH –∫–ª—é—á–µ–π –∏–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–æ–ª—è\")\n",
    "            print(\"   - –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞ –∏ –ø–æ—Ä—Ç–∞\")\n",
    "            print(\"   - –ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ REMOTE_PATH –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ\")\n",
    "            print(f\"\\n–û—à–∏–±–∫–∞: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
